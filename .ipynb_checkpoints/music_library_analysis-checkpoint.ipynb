{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas statsmodels\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading Data\n",
    "\n",
    "For this section, you will implement the `read_songs()` function. This function will take in a string representing the path to a CSV file of songs and it should return a DataFrame containing all of those songs, one per row. You will not need to modify the path to the CSV that is passed into the function.\n",
    "\n",
    "There are quite a lot of columns in the dataset! Here's a full list of them. \n",
    "\n",
    "```\n",
    "\"Track URI\",\"Track Name\",\"Artist URI(s)\",\"Artist Name(s)\",\"Album URI\",\"Album Name\",\"Album Artist URI(s)\",\"Album Artist Name(s)\",\"Album Release Date\",\"Album Image URL\",\"Disc Number\",\"Track Number\",\"Track Duration (ms)\",\"Track Preview URL\",\"Explicit\",\"Popularity\",\"ISRC\",\"Added By\",\"Added At\",\"Artist Genres\",\"Danceability\",\"Energy\",\"Key\",\"Loudness\",\"Mode\",\"Speechiness\",\"Acousticness\",\"Instrumentalness\",\"Liveness\",\"Valence\",\"Tempo\",\"Time Signature\",\"Album Genres\",\"Label\",\"Copyrights\"\n",
    "```\n",
    "At the end of this writeup, there's a full description of the purpose of each column. We won't use all of them.\n",
    "\n",
    "Pandas' `read_csv()` function allows you to create a DataFrame that contains the data stored inside of a given CSV file. The function has a huge number of options that you can pass in as *keyword arguments* in order to change how the CSV file is interpreted. You can review all of these options in [the Pandas documentation here.](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) In this case, `read_csv()` should get all of the data successfully with the default options, but the datatypes that it chooses may not always be the best ones. In particular, the `Album Release Date` column will be interpreted as a string by default. This is not \"wrong\", but it will make certain tasks more difficult later on. How you handle this is up to youâ€”the following are three (of several possible) choices for how to handle this typing issue:\n",
    "1. Choose a setting for `read_csv()` that forces Pandas to parse the column as a `datetime` object. (Less code but more documentation reading.)\n",
    "2. Replace the column after reading the CSV by using [`to_datetime()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html). In particular, you should be aware that some dates have Day, Month, and Year whereas some have just the Year. You could almost say that the format is *\"mixed\"...*(Less code but more documentation reading.)\n",
    "3. Keep the column's type as a string and just parse out the year yourself. (Less reading but more code.)\n",
    "\n",
    "Implement the `read_songs()` function. In Checkpoint 1, use the `head()` method to inspect the first few rows of your DataFrame and make sure that it looks OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_songs(filename):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `head()` to inspect the first few rows of your DataFrame and make sure that it looks OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_songs('medium.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "### A. What Does Your DataFrame Look Like?\n",
    "\n",
    "It's important to understand the broad shape of the data you plan to work with: How much of it do you have? What columns does it consist of? Do any of these columns seem more or less useful? What values are typical in each of the columns?\n",
    "\n",
    "In the following cells, you'll find a number of questions and space for you to answer them. The cells with the questions are **text cells,** meaning that what you write in them is not considered Python code. You can type whatever you want, just like you see here. There are also a few empty **code cells** that you can use to explore your DataFrameâ€”`head()`, `shape`, `info()`, and `describe()` will all be useful here. When you submit this notebook, keep your work in these code cells! They show us how you answered the more general questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA Question 1:\n",
    "\n",
    "*How many songs are in the `sharry_songs.csv` dataset? How many columns are there?*\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Replace this text with your answer & justification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write pandas code here to answer this question!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA Question 2:\n",
    "\n",
    "*Are there any columns that are entirely or mostly empty?*\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Replace this text with your answer & justification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write pandas code here to answer this question!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Exploring Distributions\n",
    "\n",
    "There are a bunch of columns included in this dataset that measure characteristics of the songs: `\"Energy\", \"Danceability\", \"Speechiness\", \"Acousticness\", \"Instrumentalness\", \"Liveness\", \"Valence\"`. These columns all store numeric values between `0` and `1` measuring the degree to which each song represents the particular characteristic. For example, a song with a `\"Danceability\"` value of `0.9` would be highly \"danceable\", a song with a `\"Valence\"` of `0.1` will be very sad, and a song with an `\"Instrumentalness\"` score of `0.9` will have very few vocals. \n",
    "\n",
    "A quick way to get a picture of a Spotify user's taste from their song data would be to plot the distributions of each of these features as a bunch of histograms. The function `song_characteristics_distributions()`, which generates a \"small multiples\" visualization, is completed for you. You can run the cell below to define the function. The following cell calls that function on the `sharry_songs.csv` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_characteristics_distributions(df):\n",
    "    \"\"\"Generate a small-multiples plot consisting of histograms of the following song characteristics:\n",
    "    - Energy\n",
    "    - Danceability\n",
    "    - Speechiness\n",
    "    - Acousticness\n",
    "    - Instrumentalness\n",
    "    - Liveness\n",
    "    - Valence\n",
    "    Make sure the resulting plot meets the following requirements. Reading the pandas documentation for\n",
    "    DataFrame.plot() will be helpful.\n",
    "    - Give the overall collection of subplots a helpful title.\n",
    "    - Arrange the plots in a 4x2 grid.\n",
    "    - Each histogram should have 40 bins.\n",
    "    - Make sure each histogram shares the same x-axis scale (from 0-1) with tick labels visible.\n",
    "    - The overall plot should be big enough to read without overlapping subplots. \n",
    "\n",
    "    Args:\n",
    "        df: a pandas.DataFrame\n",
    "    \"\"\"\n",
    "    axes = df.plot(kind='hist', y=[\"Energy\", \"Danceability\", \"Speechiness\", \"Acousticness\", \"Instrumentalness\", \"Liveness\", \"Valence\"], bins=40, sharex=False, subplots=True, title='Listener Preferences', layout=(4, 2), figsize=(15,10))\n",
    "    for row in axes:\n",
    "        for ax in row:\n",
    "            ax.set_ylabel(None)\n",
    "            ax.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_characteristics_distributions(read_songs(\"sharry_songs.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Question 3\n",
    "\n",
    "*Based on the figures above, make a claim about Harry's apparent music preferences. Or, download your own data using the process outlined above, call the function on your own data, and make a claim about your own music preferences!*\n",
    "\n",
    "Replace this text with a statement that appears to be true about the distribution of song values above. Here's one that would be wrong: Harry has no obvious preference between songs that are instrumental and those that feature vocals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Answering Questions\n",
    "\n",
    "Once we understand what our data \"looks like,\" we can formulate more specific questions that we'd like to ask about a user's library. \n",
    "\n",
    "Each of the following functions represents a kind of question you might ask about a user's library. Implement each of the functions. Keep in mind the Pandas function toolkit we've developed in class, and make sure to have [the Pandas documentation](https://pandas.pydata.org/docs/user_guide/index.html) close at hand.\n",
    "\n",
    "There are also edge cases defined for each of the functions below. \n",
    "\n",
    "*The functions are presented in roughly increasing order of complexity. Aim to complete the first two in one or two lines. The following ones will require a bit more work.*\n",
    "\n",
    "----\n",
    "\n",
    "#### Standard Deviation Tools & Tips:\n",
    "\n",
    "You'll probably find the [`.std()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.std.html) function helpful here. Remember that you need to return the standard deviation of a single column, so you'll need to select the proper one before using `.std()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_deviation_of_energy(df):\n",
    "    \"\"\"Calculates the standard deviation of the energy values in the library.\n",
    "    The standard deviation is defined as the square root of the average squared\n",
    "    difference between each value and the mean. If the library is empty, return 0.\n",
    "    Args:\n",
    "        df: a pandas.DataFrame\n",
    "    Returns:\n",
    "        a float, the standard deviation of the energy values in the library.\n",
    "    Tests:\n",
    "    >>> standard_deviation_of_energy(read_songs('small.csv'))\n",
    "    0.23676853811956278\n",
    "    >>> standard_deviation_of_energy(read_songs('medium.csv'))\n",
    "    0.23761001852234664\n",
    "    >>> standard_deviation_of_energy(read_songs('sharry_songs.csv'))\n",
    "    0.2304914250538867\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### Songs Per Year Tools & Tips:\n",
    "\n",
    "There are a few ways to approach this problem depending on what data type you're using for the `\"Album Release Date\"` column. \n",
    "\n",
    "**If you're using a `datetime` object**, then you can extract the year value from a `Series` with the [`dt.year` attribute](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.year.html). The linked documentation has an illuminating example. Once you have each song's year, you can solve the problem in one or two more steps with either filtering or [`.value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html). \n",
    "\n",
    "**If you're using a `str` object**, then you'll have to extract the year by parsing that out of the string. Inspect the column manually and see if you can identify which positions the year occupies in the date strings. (Is it the same for both date formats found in the file?) You can mimic typical Python string slicing (i.e. `s[start:stop:step]`) with the Pandas function [`str.slice()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice.html) function. Once you have a way of isolating the year, the problem can be solved with filtering or `.value_counts()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_songs_from_year(df, year):\n",
    "    \"\"\"Counts the number of songs from a specific year in the library. If the library is empty, return 0.\n",
    "    Bear in mind that the year argument is passed in as an integer. The \"Album Release Date\" column in the DataFrame\n",
    "    Args:\n",
    "        df: a pandas.DataFrame\n",
    "        year: an int\n",
    "    Returns:\n",
    "        an int, the number of songs from the specified year.\n",
    "    Tests:\n",
    "    >>> count_songs_from_year(read_songs('small.csv'), 2015)\n",
    "    4\n",
    "    >>> count_songs_from_year(read_songs('medium.csv'), 2018)\n",
    "    14\n",
    "    >>> count_songs_from_year(read_songs('sharry_songs.csv'), 2020)\n",
    "    78\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Popularity Range Tools & Tips:\n",
    "\n",
    "There are a bunch of ways to solve this one. A crucial element of the problem is excluding those rows with popularity values of `0`, and that can be done with a standard filter. \n",
    "\n",
    "To calculate the range, you need the biggest and smallest values in the series. You could get this by calling [`sort_values()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html) on a Series and then using [`.iloc[]`](https://pandas.pydata.org/docs/reference/api/pandas.Series.iloc.html) to access the proper values. Or maybe there are some other functions that might help: [`max()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.max.html) and [`min()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.min.html), perhaps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_popularity_range(df):\n",
    "    \"\"\"Calculate the range of popularity values in the library.\n",
    "    Ignore all songs with popularity value of 0. (This is a placeholder value for songs with unknown popularity.)\n",
    "    If the library is empty, return -1.\n",
    "    Args:\n",
    "        df: a pandas.DataFrame\n",
    "    Returns:\n",
    "        an int, the range of popularity values in the library (highest popularity - lowest popularity)\n",
    "    Tests:\n",
    "    >>> calculate_popularity_range(read_songs('small.csv'))\n",
    "    29\n",
    "    >>> calculate_popularity_range(read_songs('medium.csv'))\n",
    "    76\n",
    "    >>> calculate_popularity_range(read_songs('sharry_songs.csv'))\n",
    "    92\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Song Name with Most Genres Tools & Tips:\n",
    "\n",
    "Think back to counting bus routes to NYC schools from 10/16, but with genres instead of songs. Note that the `\"Artist Genres\"` column stores strings the genres separated by commas. As a reminder, here are some important string/list processing functions in Pandas. You won't need all of them.\n",
    "\n",
    "- [`str.count(substring)`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.count.html) counts the occurrences of a substring in a string\n",
    "- [`str.contains(substring)`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html) returns `True` if the substring is present in the larger string in that cell\n",
    "- [`str.split(sep)`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) splits the string into a list of substrings separated by `sep`\n",
    "- [`str.len()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.len.html) finds the length of the string (or list!) in this cell and returns it as a number\n",
    "\n",
    "Keep in mind that you need to break ties by selecting the song that appears closer to the top of the `DataFrame`. When you filter rows out of a `DataFrame`, the order of the rows is otherwise preserved. You can use this to your advantage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_name_with_most_genres(df):\n",
    "    \"\"\"Finds the song with the most genres in the library and returns its name.\n",
    "    If the library is empty, return None.\n",
    "    If there are multiple songs with the same number of genres, return the one that appears earlier in the library.\n",
    "    Args:\n",
    "        df: a pandas.DataFrame\n",
    "    Returns:\n",
    "        a string, the name of the song with the most genres.\n",
    "    Tests:\n",
    "    >>> song_name_with_most_genres(read_songs('small.csv'))\n",
    "    'Give Your Heart Away'\n",
    "    >>> song_name_with_most_genres(read_songs('medium.csv'))\n",
    "    'american dream'\n",
    "    >>> song_name_with_most_genres(read_songs('sharry_songs.csv'))\n",
    "    '...And The World Laughs With You'\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Song Name with Most Genres Tools & Tips:\n",
    "\n",
    "This problem deals with string processing again, so here are some important string/list processing functions in Pandas. You won't need all of them.\n",
    "\n",
    "- [`str.count(substring)`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.count.html) counts the occurrences of a substring in a string\n",
    "- [`str.contains(substring)`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html) returns `True` if the substring is present in the larger string in that cell\n",
    "- [`str.split(sep)`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) splits the string into a list of substrings separated by `sep`\n",
    "- [`str.len()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.len.html) finds the length of the string (or list!) in this cell and returns it as a number\n",
    "\n",
    "ðŸ¤¯ [Exploding](https://pandas.pydata.org/docs/reference/api/pandas.Series.explode.html) the `DataFrame` might be useful. Remember that this function works by expanding the `DataFrame` to include many \"duplicate\" rows, creating each one of these duplicates for each value in the list cell that's being exploded. The example from 10/18 may be helpful here. There are probably half a dozen ways of doing this, though, so you may have some luck perusing the Pandas documentation to find an answer. Just keep in mind that you want to match on **full artist names.** If I'm searching for songs by `\"Future\"`, you should not return any songs by the artist `\"Future Islands\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_songs_with_artist(df, artist):\n",
    "    \"\"\"Selects all songs by a specific artist in the library.\n",
    "    Keep in mind that a song may have many artists. The song\n",
    "    should be included in the output if *any* of its artists\n",
    "    match the input. You should not modify the input DataFrame, but\n",
    "    you can create a copy using the .copy() method.\n",
    "    If the library is empty, the DataFrame returned should be empty.\n",
    "    Args:\n",
    "        df: a pandas.DataFrame\n",
    "        artist: a string\n",
    "    Returns:\n",
    "        a DataFrame containing only songs featuring the specified artist.\n",
    "    Tests:\n",
    "    >>> find_songs_with_artist(read_songs('medium.csv'), 'Slash').shape[0]\n",
    "    2\n",
    "    >>> find_songs_with_artist(read_songs('medium.csv'), 'Slash')['Track Name'].iloc[0]\n",
    "    'Starlight (feat. Myles Kennedy)'\n",
    "    >>> find_songs_with_artist(read_songs('medium.csv'), 'Slash')['Track Name'].iloc[1]\n",
    "    'Watch This'\n",
    "    >>> find_songs_with_artist(read_songs('sharry_songs.csv'), 'Phoebe Bridgers').shape[0]\n",
    "    13\n",
    "    >>> find_songs_with_artist(read_songs('sharry_songs.csv'), 'Phoebe Bridgers')['Track Name'].iloc[0]\n",
    "    'Leonard Cohen'\n",
    "    >>> find_songs_with_artist(read_songs('sharry_songs.csv'), 'Phoebe Bridgers')['Track Name'].iloc[1]\n",
    "    'Motion Sickness'\n",
    "    >>> find_songs_with_artist(read_songs('sharry_songs.csv'), 'Phoebe Bridgers')['Track Name'].iloc[12]\n",
    "    'Dominos'\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tracking Genres over Time\n",
    "\n",
    "Spotify has a huge set of music genres that it uses to tag each song. Some of the genres they use are remarkably specific (\"duluth indie\"), totally obtuse (\"bubblegrunge\"), or just plain silly (\"y'alternative\" ðŸ¤ ). It's possible to get a sense of what a genre is supposed to refer to by listening to songs tagged with it, but it's also useful to understand the genres in the context of the timeframe from which its constituent songs come. Furthermore, many genres of music evolve significantly over timeâ€”compare Future to Run-DMC or Johnny Cash to Florida Georgia Line, for example. \n",
    "\n",
    "For this next task, help by completing the `genre_frequency_over_time()` function to generate a bar chart counting the number of songs matching a given genre in all years between its first appearance in the dataset to its last. The chart must be a bar chart with a title **that displays the name of the genre** and helpful x- and y- axes labels. (You can make it look nicer if you likeâ€”coloring the bars by release year could be a lot of fun!) By using [`plot()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.html), you should be able to finish this task in just one or two additional lines of code. Keep in mind that `by_year`â€”the data you should be plottingâ€”is a `Series`, so you won't need to specify the columns to use for the x and y dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_frequency_over_time(df, genre):\n",
    "    \"\"\"Generate a bar plot showing the number of songs of a specific genre by year.\n",
    "    The x-axis should be the year, and the y-axis should be the number of songs.\n",
    "    The first year and last years should be the first and last years that the genre\n",
    "    appears in the library. All intermediate years should be included, even if there are no songs\n",
    "    with that genre in that year. reindex() is useful for this.\n",
    "    Make sure to add axis labels and a title that mentions the name of the genre being plotted.\n",
    "    Args:\n",
    "        df: a pandas.DataFrame\n",
    "        genre: a string\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    copied = df.copy()\n",
    "    copied[\"Artist Genres\"] = copied[\"Artist Genres\"].str.split(\",\")\n",
    "    exploded = copied.explode('Artist Genres')\n",
    "    exploded = exploded[exploded[\"Artist Genres\"] == genre]\n",
    "\n",
    "    exploded[\"Album Release Date\"] = pd.to_datetime(exploded[\"Album Release Date\"], format=\"mixed\")\n",
    "    by_year = exploded.groupby(exploded[\"Album Release Date\"].dt.year).size()\n",
    "    by_year = by_year.reindex(range(by_year.index.min(), by_year.index.max() + 1), fill_value=0)\n",
    "    ## ADD CODE HERE!\n",
    "\n",
    "genre_frequency_over_time(read_songs('sharry_songs.csv'), 'indie pop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell here runs all of the tests that are encoded into the function docstrings above. It's a nice way of testing your output. You can add your own tests, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest\n",
    "doctest.testmod(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. What Is My Kind of Song?\n",
    "\n",
    "For the final part of this assignment, you are given a model that is designed to estimate the probability of whether some **new** song would fit into my library or not. You are tasked with running some cells here and thinking critically about the model as it has been described. You will not write code here, but you will have to answer a few open-ended questions and provide some justification. \n",
    "\n",
    "The main hypothesis that drives the model we have built is that the songs that I have saved to my library might tend to fit a certain profile. Maybe my taste is, for example, happy, high-energy, acoustic-sounding music. In order to prove that, it will be important to have examples of songs that are not currently among my Liked Songs. \n",
    "\n",
    "These come from an anonymous friendâ€”let's call her \"E\"â€”and are found in the file called `other_songs.csv`. By introducing songs that come from another libraryâ€”from another person with a different taste for musicâ€”we might introduce some examples that have notably different musical profiles. This will give our model a notion of what music outside of my personal taste might look like so that it can learn to identify examples of it. Then, the model will be tasked with estimating the probability that a song with a certain profile comes from my library instead of E's library.\n",
    "\n",
    "The model is actually built using the steps outlined in the included `building_a_model.ipynb`. You do not have to read anything or run any code found in that notebook, but it does show you how the model is built if you're curious. We can load the model using the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# This will print a summary of the model, which helps to confirm that\n",
    "# the model was loaded correctly. For more info on some of these numbers,\n",
    "# you can check out building_a_model.ipynb\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well the model works on three different songs that I do really like, but that are not present in `sharry_songs.csv`. In each case, I have queried Spotify to get the song features for these songs and copied them manually into three individual DataFrames. Make sure to run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_laundry = pd.DataFrame({\n",
    "  \"Track Name\": \"Dirty Laundry\",\n",
    "  \"Artist Name(s)\" : \"Cayetana\",\n",
    "  \"Acousticness\": 0.0021,\n",
    "  \"Danceability\": 0.319,\n",
    "  \"Energy\": 0.892,\n",
    "  \"Instrumentalness\": 0.0528,\n",
    "  \"Liveness\": 0.187,\n",
    "  \"Speechiness\": 0.054,\n",
    "  \"Valence\": 0.749\n",
    "}, index=[0])\n",
    "\n",
    "unlimited_love = pd.DataFrame({\n",
    "    \"Track Name\": \"Unlimited Love\",\n",
    "    \"Artist Name(s)\": \"thanks for coming\",\n",
    "  \"Acousticness\": 0.574,\n",
    "  \"Danceability\": 0.851,\n",
    "  \"Energy\": 0.537,\n",
    "  \"Instrumentalness\": 0,\n",
    "  \"Liveness\": 0.302,\n",
    "  \"Speechiness\": 0.0525,\n",
    "  \"Valence\": 0.965,\n",
    "  \"track_href\": \"https://api.spotify.com/v1/tracks/7I8DFjHKnjZP2ExgK5gqHK\"\n",
    "}, index=[0])\n",
    "\n",
    "red_wine_supernova = pd.DataFrame({\n",
    "    \"Track Name\": \"Red Wine Supernova\",\n",
    "    \"Artist Name(s)\": \"Chappell Roan\",\n",
    "    \"Acousticness\": 0.0176,\n",
    "    \"Danceability\": 0.657,\n",
    "    \"Duration_ms\": 192721,\n",
    "    \"Energy\": 0.82,\n",
    "    \"Instrumentalness\": 0,\n",
    "    \"Liveness\": 0.0847,\n",
    "    \"Speechiness\": 0.0441,\n",
    "    \"Valence\": 0.709,\n",
    "    \"track_href\": \"https://api.spotify.com/v1/tracks/7FOgcfdz9Nx5V9lCNXdBYv\"\n",
    "}, index=[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask what the model thinks about the probability of each song being mine by calling the `predict()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(dirty_laundry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model estimates a $93\\%$ probability that this song is one of mine instead of being one of E's. That is a fair bet in this caseâ€”I think that the [lo-fi indie punk sound](https://www.youtube.com/watch?v=z0DKtKTQaL0) is one that I like much more than her. OK, so what about the next one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(unlimited_love)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, [\"Unlimited Love\"](https://www.youtube.com/watch?v=1buPD4MGslA) is a recent favorite song of mine, but the model seems to think it's more likely to be one of E's songs! (Only a $31.8\\%$ of being mine, so a $68.2\\%$ chance of being hers...) Curiousâ€”it doesn't feel so far off from a lot of stuff I like, but perhaps it's statistically more like E's music.\n",
    "\n",
    "How about the last one? It's a little out of my wheelhouse, but I've been enjoying [this Chappell Roan song](https://www.youtube.com/watch?v=y9Wxl9Q9lUQ) recently. Let's see what the model thinks about the chances of it being one of mine instead of one of E's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(red_wine_supernova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so not so surprising to the model that I would like the songâ€”apparently it's got a $77.5\\%$ chance of being mine instead of E's. But wait a second... E actually beat me to the punch in this case, and the song is already present in her library! We actually told the model that \"Red Wine Supernova\" is one of E's songs when we were teaching it the difference between my songs and hers. This reveals one of the challenges of probabilistic models trained on lots of data: models like this are responsible for capturing large, overarching patterns, and so the model can learn patterns that contradict individual examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "Please answer the following questions and give your best answer. You are encouraged to keep your answer to just a few sentences in each case, but you should make sure to give your answer some justification. These questions are designed to get you thinking about the use of statistical models built on personal data. There are several acceptable answers to each question, and an answer need not be absolutely \"correct\" in order to be considered acceptable. You are welcome to discuss these questions with a partner, but if you do, you must cite each other and also **describe your discussion:** Did you come to the same conclusion? Did you propose two different answers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "\n",
    "In order to train our model, we needed examples of songs that were \"Harry Songs\" and \"not Harry Songs.\" How did we find examples of \"not Harry Songs?\" What are the implications of the \"not Harry Songs\" that we used for the kinds of conclusions that we can draw based on this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<write your answer here!>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "\n",
    "Notice that when we call the `predict()` function from our model, we get a `float` representing the probability of a song being a \"Harry Song.\" Why might it be a good thing that the model outputs *probabilities* and not *booleans/\"yes or no\"* answers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<write your answer here!>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "\n",
    "Reflect on the results of the three predictions we asked the model to make. Do they make you feel that the model is trustworthy or untrustworthy, or do you feel that you don't have enough information? How could we get a better sense of how good the model actually is? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<write your answer here!>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "\n",
    "Conclude this assignment by making a suggestion about how we could make this model *better.* (\"Better\" is a subjective term that could have plenty of meanings in this case, so please explain in what way you think your suggestion will actually make things better!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<write your answer here!>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readme\n",
    "\n",
    "### How much time did you spend on this assignment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<write your answer here!>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What was the most challenging aspect of this assignment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<write your answer here!>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please list all sources you used to complete this assignment. (You can leave out TA & Instructor help on Ed and in Office Hours.) Name your collaborators for Part 5 here too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<write your answer here!>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
